---
title: 'Project 1: Exploratory Data Analysis'
author: "Madelyn Oliveri"
date: 'October 18, 2020'
output:
  html_document:
    toc: yes
    toc_float:
      collapsed: no
      smooth_scroll: yes
  pdf_document:
    toc: no
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, eval = TRUE, fig.align = "center", warning = F, message = F,
tidy=TRUE, tidy.opts=list(width.cutoff=60), R.options=list(max.print=100))
```

*In this study I will be comparing motor vehicle data alongside U.S civilian house fire data; in-particular, examining trends in the number of deaths over the years from each type of accident, with the common variable being the year (1960-2018). Motor vehicle accident data was collected from the Bureau of Transportation Statistics which includes motorcycles while excluding commercial vehicles. It includes the number of crashes, the total number of deaths (presented as Deaths.x), as well as the estimated number of registered drivers (in millions). House-fire data was retrieved from the National Fire Protection Association research articles on “Home Structure Fires”. The variables include the most-prevalent cause of fire (such as electrical, cooking, etc.), reported property damage (in U.S. billions), and the total number of deaths each year (presented as ‘Deaths.y’) which are all categorized by yearly totals.

*I am interested in this data due to the last decade’s rapid advancement in technology. Two potential associations I expect could be an increase in vehicle crashes and deaths due to distracted driving (texting, social apps, etc.) while a decrease in house fires from these same advancements. This predicted trend may be valid as safety policies, and therefore, safety features on appliances improve to protect against accidental house fires.

```{R}
library(tidyverse)
library(dplyr)
library(ggplot2)

library(readr)

cars1 <- read_csv("~/cars1.csv", col_types = cols(Crashes = col_number(), 
     Deaths = col_number(), Estimated_Drivers = col_number()))
view(cars1)

library(readr)
 housefires <- read_csv("~/housefires.csv", 
     col_types = cols(Deaths = col_number(), 
         Property_Damage = col_number()))
view(housefires)

#load and name datasets

cars1$Year <- as.numeric(as.double(cars1$Year)) #Convert ‘double’ type to numeric, convert ‘character’ value to numeric
housefires$Year <- as.numeric(as.character(housefires$Year))

fj <- full_join(cars1, housefires, by = c(Year = "Year")) 
view(fj)
```
*The common variable is 'year', with only one observation per year, per column. Additionally both datasets contain similar numeric categories with only one categorical variable present, making a full_join the easiest and most appropriate way to merge data. This keeps all columns and rows present which we will need for future graphs and comparisons. No cases needed to be dropped since data was already tidy/ no NAs.

```{R}
filtered <- fj%>% filter(Property_Damage >= 7, Deaths.y <= 4000, 
    Year > 1990) %>% head() #Creating a new dataframe ‘filtered’ that creates an output only if all criteria is met through the filtered settings
```
*Property damage is greater than or equal to seven billion, while house fire deaths (.y) are less than or equal to 4000 people, and the year must be greater than 1990.

```{R}
fj %>% select_if(is.numeric) %>% select_if(~mean(.) > 3500)
```
*The select_if() command performs an operation on variables that satisfy a logical criteria. In this case we are selecting data if the mode is numeric -whether the type be integer or double-, and then within the numeric columns, we are only observing data if the average is greater than 3,500. If the set were to yield missing values, then we would include “(na.rm=TRUE)”, but it is not necessary in this case.

```{R}
fj %>% arrange(Prevalent_Cause) %>% head() #The full joined dataset is being re-arranged by the categorical variable describing the most common cause of house fires that year into chunked rows for a different way of visualizing the data.

#These include children, cooking, electrical, flammables, and heating.
```

```{R}
newvars <- fj %>% mutate(death_proportion = Deaths.y/Deaths.x, 
    pd_euros = Property_Damage * 0.85)
newvars <- newvars[-c(3, 4, 7)]
view(newvars) #A new dataset is created to show two new variables from two different mutations.
```
*The first mutation is the proportion of house fire deaths to motor vehicle deaths. The second mutation takes house fire property damage in U.S. dollars (billions) and converts to European currency.
```{R}
cars1%>%summarize_if(is.numeric, max)%>% data.frame
housefires%>%summarize_if(is.numeric, max)%>%data.frame
#Data is summarized by the maximum value in each numeric category

correlation <- fj[-c(7)]
cor(correlation, method = "pearson", use = "complete.obs")

cortable <- cor(correlation, method = "pearson", use = "complete.obs")
knitr::kable(cortable) #Correlation between all numeric variables and presented in a table using kable
```
*There is not much correlation. However there is a strong positive correlation between the estimated number of drivers and the year. As the years continue, there are more registered drivers.

```{R}
fjnumbers <- fj[-c(1, 7)]
summary <- fjnumbers %>% 
summarise(avg_deathsx = mean(Deaths.x), min_deathsx = min(Deaths.x), 
    max_deathsx = max(Deaths.x), quant_deathsx = quantile(Deaths.x), 
    sd_deathsx = sd(Deaths.x), var_deathsx = var(Deaths.x), ndis_deathsx = n_distinct(Deaths.x), 
    total_deathsx = n(), avg_deathsy = mean(Deaths.y), min_deathsy = min(Deaths.y), 
    max_deathsy = max(Deaths.y), quant_deathsy = quantile(Deaths.y), 
    sd_deathsy = sd(Deaths.y), var_deathsy = var(Deaths.y), ndis_deathsy = n_distinct(Deaths.y), 
    total_deathsy = n(), avg_Crashes = mean(Crashes), min_Crashes = min(Crashes), 
    max_Crashes = max(Crashes), quant_Crashes = quantile(Crashes), 
    sd_Crashes = sd(Crashes), var_Crashes = var(Crashes), ndis_Crashes = n_distinct(Crashes), 
    total_Crashes = n(), avg_pd = mean(Property_Damage), min_pd = min(Property_Damage), 
    max_pd = max(Property_Damage), quant_pd = quantile(Property_Damage), 
    sd_pd = sd(Property_Damage), var_pd = var(Property_Damage), 
    ndis_pd = n_distinct(Property_Damage), total_pd = n())
#A summary of statistics on all numeric variables
```
*average vehicle deaths: 43,234.54 minimum amount of vehicle deaths: 32,479 maximum amount of vehicle deaths: 54,589 quantile:32,479 standard deviation: 5833.071 variance: 34,024,714 distinct cases: 59 total: 59

*average house fire deaths: 5,083 minimum amount of house fire deaths: 2,855 maximum amount of house fire deaths: 7,710 quantile: 2855 standard deviation: 1,424 variance: 2,028,811 distinct cases: 57 total: 59

*average number of crashes: 37,034 minimum number of crashes: 29,867 maximum number of crashes: 45,284 quantile: 29,867 standard deviation: 3,768 variance:14,204,783 number of distinct crashes: 59 total: 59

*average property damage: $8.856 billion minimum property damage: $3 billion maximum property damage: $44 billion quantile: $8.2 billion standard deviation: $6.483 billion variance: 42.03 distinct cases: 50 total: 59

```{R}
housefires %>% group_by(Prevalent_Cause) %>% 
summarise(avg_housedeaths = mean(Deaths), min_housedeaths = min(Deaths), 
    max_housedeaths = max(Deaths), quant_housedeaths = quantile(Deaths), 
    sd_housedeaths = sd(Deaths), var_housedeaths = var(Deaths), 
    ndis_housedeaths = n_distinct(Deaths), total = n())
#Summary of house fire deaths grouped by the prevalent cause

housefires$Category[housefires$Deaths >= 3500] = "High"
housefires$Category[housefires$Deaths < 3500] = "Low"
#Adds column 'Category' and assigns deaths greater than or equal to 3,500 as high and less than 3,500 as low

housefires %>% pivot_wider(names_from = Prevalent_Cause, values_from = Year, 
    values_fill = 0)
#Increases number of columns by listing each prevalent house fire cause and assigning the years to them
```
*So if the most common type of house fire was from cooking in 1960, then 1960 would go under that category along with other years when cooking was the most prevalent.

```{R}
cars1$Category[cars1$Crashes >= 35000] = "High"
cars1$Category[cars1$Crashes < 35000] = "Low"
#Categorizes the number of vehicle crashes into “High” if there are 35,000 or more and “Low” if there are fewer

pivot_longer(cars1, cols = c("Category"), names_to = "Death", 
    values_to = "Year", names_repair = "unique")
#Increases the number of rows

house <- housefires %>% group_by(Category) %>% summarise(min_pc = min(Prevalent_Cause), 
    max_pc = max(Prevalent_Cause), ndis_pc = n_distinct(Prevalent_Cause), 
    total = n())
#Two categorical variables are related through summarizing the data on the common cause of fire displayed within the groups ‘high’ or ‘low’ amount of deaths.
```
*With 3,500 or more deaths, the least common cause of a house fire was due to children and the most common cause was from heating a house. With fewer than 3,500 deaths, the least common cause of fires was cooking and the most common was heating the house (again). The number of unique variables grouped by high death rate is 6 and for low death rate is 3. The total number of observations for high amounts of deaths is 46 and low amounts of deaths, 13.

```{R}
summary(correlation)
apply(correlation, 2, sd)
apply(correlation, 2, var)
apply(correlation, 2, n_distinct)
#Utilizes the ‘correlation’ dataset to produce all statistics for numeric variables by column
```

```{R}
library(corrplot)
library(ggplot2)

correlation = fj[1:6]
cormat <- round(cor(correlation),2)

library(reshape2)
melted_cormat <- melt(cormat)


get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}

get_upper_tri <- function(cormat){
cormat[lower.tri(cormat)]<- NA
return(cormat)
}

upper_tri <- get_upper_tri(cormat)


melted_cormat <- melt(upper_tri, na.rm = TRUE)

ggheatmap <- ggplot(melted_cormat, aes(Var2, Var1, fill = value))+
    geom_tile(color = "white")+
    scale_fill_gradient2(low = "blue", high = "red", mid = "white", 
                         midpoint = 0, limit = c(-1,1), space = "Lab", 
                         name="Pearson\nCorrelation") +
    theme_minimal()+ # minimal theme
    theme(axis.text.x = element_text(angle = 45, vjust = 1, 
                                     size = 12, hjust = 1))+
    coord_fixed()


ggheatmap + 
    geom_text(aes(Var2, Var1, label = value), color = "black", size = 4) +
    theme(
        axis.title.x = element_blank(),
        axis.title.y = element_blank(),
        panel.grid.major = element_blank(),
        panel.border = element_blank(),
        panel.background = element_blank(),
        axis.ticks = element_blank(),
        legend.justification = c(1, 0),
        legend.position = c(0.6, 0.7),
        legend.direction = "horizontal")+
    guides(fill = guide_colorbar(barwidth = 7, barheight = 1,
                                 title.position = "top", title.hjust = 0.5))
#Produces Pearson correlation map to easily view the correlation between all numberic variable.
```
*There are some trends shown on the Pearson correlation graph. There is a small positive correlation between the number of deaths due to crahses and deaths due to housefires. There is another positive correlation between property damage and the year. Additionally, there is a negative correlation between the number of house fire deaths and the year which could support the idea that safety features on technology and appliances has increased to prevent fires.

```{R}
fj %>% ggplot(aes(x = Prevalent_Cause, y = Property_Damage, fill = Prevalent_Cause, 
    color = "black")) + geom_boxplot() + theme(legend.position = "bottom") + 
    ggtitle("Distribution of Property Damage Cost in U.S. Billions by Fire Type")
```
*Boxplots comparing trends in property damage as categorized by type of fire. There are three outliers for the amount of property damage, two of which fall under cooking which could skew the data. Flammables caused the least amount of propery damage expenses while all other categories are failry similar in costs.

```{R}
ggplot(housefires, aes(x = Year, y = Property_Damage, color = Category)) + 
    geom_point(size = 3, alpha = 0.5) + geom_line() + theme(legend.position = "bottom") + 
    ggtitle("Property Damage by Year") + xlab("Year") + ylab("Reported Property Damage (billions)") + 
    scale_y_continuous(breaks = seq(0, 45, 5)) + stat_summary(fun = mean, 
    color = "black", size = 0.5)
```
*A different way of showing property damage trends throughout the years, but instead, categorized by high and low amounts of deaths. There have been a lower amount of house fire deaths from 2000 onward.This graph also shows that property damage has steadily increased over the years. This could be due to inflation in the US Economy.

```{R}
library(cluster)
library(factoextra)

library(ggplot2)
library(ggfortify)

fjnumbers <- fj[-c(1, 7)]
pamfj <- pam(fjnumbers, 3, keep.diss = TRUE)
plot(pamfj)
#k clusters/PAM, graphs
```
*Three clusters is best because it is most uniformly grouped. The silhouette graphs help measure how close each point in one cluster is to points in the neighboring clusters. A trong structure is found between 0.71 to 1.00. A reasonable structure lies between 0.51 to 0.70. A weak structure is about 0.26 to 0.50. There is no substantial structure if between -1 to 0.25.In this case, two clusters have a reasonable structure with values of 0.54 while the third has a weak structre with a value of 0.35.

```{R}
autoplot(pam(fjnumbers, 3), frame = TRUE, frame.type = "norm")
```
